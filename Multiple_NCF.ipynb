{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmdfFoteOrjB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ITvL14iOvQ_"
      },
      "outputs": [],
      "source": [
        "# === Part 1: Data Loading and Preprocessing ===\n",
        "def load_and_preprocess_data():\n",
        "    user_place_data = pd.read_csv('https://raw.githubusercontent.com/NhatMinh2910/Pre-thesis-Datasets/refs/heads/main/rats.csv')\n",
        "    user_features = pd.read_csv('https://raw.githubusercontent.com/NhatMinh2910/Pre-thesis-Datasets/refs/heads/main/ufeat.csv')\n",
        "\n",
        "    # Keep only needed columns\n",
        "    user_features = user_features[['user_id', 'Age', 'Gender', 'Budget', 'GroupComp']]\n",
        "\n",
        "    # Fill missing values\n",
        "    user_features.fillna(0, inplace=True)\n",
        "\n",
        "    # Map Gender to numeric\n",
        "    user_features['Gender'] = user_features['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "    # One-hot encode GroupComp\n",
        "    user_features = pd.get_dummies(user_features, columns=['GroupComp'])\n",
        "\n",
        "    # Encode user_id and place_id\n",
        "    user_encoder = LabelEncoder()\n",
        "    item_encoder = LabelEncoder()\n",
        "\n",
        "    user_place_data['user_id'] = user_encoder.fit_transform(user_place_data['user_id'])\n",
        "    user_place_data['place_id'] = item_encoder.fit_transform(user_place_data['place_id'])\n",
        "\n",
        "    # Normalize rating\n",
        "    if user_place_data['rating'].max() > 1:\n",
        "        user_place_data['rating'] = user_place_data['rating'] / user_place_data['rating'].max()\n",
        "\n",
        "    # Merge user features\n",
        "    user_place_data = user_place_data.merge(user_features, on='user_id', how='left')\n",
        "\n",
        "    return user_place_data, user_encoder, item_encoder, user_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwjUUKkVOzuV"
      },
      "outputs": [],
      "source": [
        "# === Part 2: Prepare Inputs and Train-Test Split ===\n",
        "def prepare_data(user_place_data, user_features):\n",
        "    X_user_place = user_place_data[['user_id', 'place_id']].values\n",
        "    y = user_place_data['rating'].values\n",
        "\n",
        "    # Extract user features columns except 'user_id'\n",
        "    feature_cols = [c for c in user_features.columns if c != 'user_id']\n",
        "    X_user_features = user_place_data[feature_cols].values.astype(np.float32)\n",
        "\n",
        "    # Apply weights: Age (0.3), Gender (0.3), Budget (0.2), each GroupComp column (0.2 total split evenly)\n",
        "    # First find indices of each attribute in X_user_features\n",
        "    age_idx = feature_cols.index('Age')\n",
        "    gender_idx = feature_cols.index('Gender')\n",
        "    budget_idx = feature_cols.index('Budget')\n",
        "\n",
        "    # GroupComp columns (all other columns except Age, Gender, Budget)\n",
        "    groupcomp_indices = [i for i, c in enumerate(feature_cols) if c.startswith('GroupComp_')]\n",
        "\n",
        "    # Number of GroupComp columns\n",
        "    n_groupcomp = len(groupcomp_indices)\n",
        "    if n_groupcomp == 0:\n",
        "        raise ValueError(\"No GroupComp columns found after one-hot encoding.\")\n",
        "\n",
        "    # Define weights per feature\n",
        "    weights = np.ones(X_user_features.shape[1], dtype=np.float32) * 0.0\n",
        "    weights[age_idx] = 0.3\n",
        "    weights[gender_idx] = 0.3\n",
        "    weights[budget_idx] = 0.2\n",
        "    # Distribute GroupComp total weight 0.2 evenly\n",
        "    for idx in groupcomp_indices:\n",
        "        weights[idx] = 0.2 / n_groupcomp\n",
        "\n",
        "    # Apply weights by multiplying feature columns\n",
        "    X_user_features_weighted = X_user_features * weights\n",
        "\n",
        "    # Train test split\n",
        "    X_train, X_test, y_train, y_test, user_feat_train, user_feat_test = train_test_split(\n",
        "        X_user_place, y, X_user_features_weighted, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Convert inputs to proper dtypes\n",
        "    X_train_user = np.array(X_train[:, 0], dtype=np.int32)\n",
        "    X_train_place = np.array(X_train[:, 1], dtype=np.int32)\n",
        "    user_feat_train = np.array(user_feat_train, dtype=np.float32)\n",
        "    y_train = np.array(y_train, dtype=np.float32)\n",
        "\n",
        "    X_test_user = np.array(X_test[:, 0], dtype=np.int32)\n",
        "    X_test_place = np.array(X_test[:, 1], dtype=np.int32)\n",
        "    user_feat_test = np.array(user_feat_test, dtype=np.float32)\n",
        "    y_test = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "    return (X_train_user, X_train_place, user_feat_train, y_train,\n",
        "            X_test_user, X_test_place, user_feat_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFAVKrL7O7fL"
      },
      "outputs": [],
      "source": [
        "# === Part 3: Build the NCF Model ===\n",
        "def build_ncf_model(num_users, num_items, user_feat_dim, embedding_size=50):\n",
        "    user_input = Input(shape=(1,), name='user_input')\n",
        "    place_input = Input(shape=(1,), name='place_input')\n",
        "    user_features_input = Input(shape=(user_feat_dim,), name='user_features_input')\n",
        "\n",
        "    user_embedding = Embedding(num_users, embedding_size,\n",
        "                               embeddings_regularizer=tf.keras.regularizers.l2(1e-6),\n",
        "                               name='user_embedding')(user_input)\n",
        "    place_embedding = Embedding(num_items, embedding_size,\n",
        "                                embeddings_regularizer=tf.keras.regularizers.l2(1e-6),\n",
        "                                name='place_embedding')(place_input)\n",
        "\n",
        "    user_flat = Flatten()(user_embedding)\n",
        "    place_flat = Flatten()(place_embedding)\n",
        "\n",
        "    # Concatenate embeddings and weighted user features\n",
        "    combined = Concatenate()([user_flat, place_flat, user_features_input])\n",
        "\n",
        "    x = Dense(128, activation='relu')(combined)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(1, activation='linear')(x)\n",
        "\n",
        "    model = Model(inputs=[user_input, place_input, user_features_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaPuemAmO-zb"
      },
      "outputs": [],
      "source": [
        "# === Part 4: Evaluation Function ===\n",
        "def evaluate_model(model, X_test_list, y_test):\n",
        "    y_pred = model.predict(X_test_list)\n",
        "    rmse = np.sqrt(np.mean((y_test - y_pred.flatten())**2))\n",
        "\n",
        "    y_pred_bin = (y_pred.flatten() >= 0.5).astype(int)\n",
        "    y_test_bin = (y_test >= 0.5).astype(int)\n",
        "\n",
        "    auc_roc = roc_auc_score(y_test_bin, y_pred_bin)\n",
        "    accuracy = np.mean(y_pred_bin == y_test_bin)\n",
        "\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return accuracy, rmse, auc_roc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03iCYRltPFyp",
        "outputId": "053fab78-3f2a-45fa-9c6a-55dd678b112d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 73ms/step - loss: 0.0408 - val_loss: 0.0287\n",
            "Epoch 2/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 73ms/step - loss: 0.0249 - val_loss: 0.0286\n",
            "Epoch 3/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 73ms/step - loss: 0.0190 - val_loss: 0.0289\n",
            "Epoch 4/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 73ms/step - loss: 0.0161 - val_loss: 0.0295\n",
            "Epoch 5/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 73ms/step - loss: 0.0148 - val_loss: 0.0292\n",
            "Epoch 6/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 73ms/step - loss: 0.0139 - val_loss: 0.0288\n",
            "Epoch 7/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 73ms/step - loss: 0.0133 - val_loss: 0.0288\n",
            "Epoch 8/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 74ms/step - loss: 0.0131 - val_loss: 0.0287\n",
            "Epoch 9/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 74ms/step - loss: 0.0127 - val_loss: 0.0284\n",
            "Epoch 10/10\n",
            "\u001b[1m3886/3886\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 77ms/step - loss: 0.0125 - val_loss: 0.0284\n",
            "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
            "Test RMSE: 0.1584\n",
            "Test Accuracy: 0.7889\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
            "Predicted Rating: 0.6009\n"
          ]
        }
      ],
      "source": [
        "# === Part 5: Main Execution ===\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_accuracy(y_true, y_pred, threshold=0.5):\n",
        "    y_pred_bin = (y_pred.flatten() >= threshold).astype(int)\n",
        "    y_true_bin = (y_true >= threshold).astype(int)\n",
        "    return accuracy_score(y_true_bin, y_pred_bin)\n",
        "\n",
        "def main():\n",
        "    user_place_data, user_encoder, item_encoder, user_features = load_and_preprocess_data()\n",
        "\n",
        "    (X_train_user, X_train_place, user_feat_train, y_train,\n",
        "     X_test_user, X_test_place, user_feat_test, y_test) = prepare_data(user_place_data, user_features)\n",
        "\n",
        "    model = build_ncf_model(\n",
        "        num_users=len(user_encoder.classes_),\n",
        "        num_items=len(item_encoder.classes_),\n",
        "        user_feat_dim=user_feat_train.shape[1]\n",
        "    )\n",
        "\n",
        "    model.fit([X_train_user, X_train_place, user_feat_train], y_train,\n",
        "              epochs=10, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict([X_test_user, X_test_place, user_feat_test])\n",
        "\n",
        "    # Calculate RMSE\n",
        "    rmse = np.sqrt(np.mean((y_test - y_pred.flatten()) ** 2))\n",
        "    print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy = compute_accuracy(y_test, y_pred)\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Example prediction\n",
        "    user_id_example = 1\n",
        "    place_id_example = 2\n",
        "\n",
        "    # Prepare example user features vector with weights applied (adjust indices as needed)\n",
        "    user_features_example = np.zeros((1, user_feat_train.shape[1]), dtype=np.float32)\n",
        "    age_idx = user_features.columns.get_loc('Age') - 1\n",
        "    gender_idx = user_features.columns.get_loc('Gender') - 1\n",
        "    budget_idx = user_features.columns.get_loc('Budget') - 1\n",
        "    groupcomp_cols = [i-1 for i, c in enumerate(user_features.columns) if c.startswith('GroupComp_')]\n",
        "\n",
        "    user_features_example[0, age_idx] = 30 * 0.3\n",
        "    user_features_example[0, gender_idx] = 1 * 0.3\n",
        "    user_features_example[0, budget_idx] = 500 * 0.2\n",
        "    for i in groupcomp_cols:\n",
        "        user_features_example[0, i] = 0  # or set one group to 0.2/n_groupcomp\n",
        "\n",
        "    pred = model.predict([np.array([user_id_example]), np.array([place_id_example]), user_features_example])\n",
        "    print(f\"Predicted Rating: {pred[0][0]:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
